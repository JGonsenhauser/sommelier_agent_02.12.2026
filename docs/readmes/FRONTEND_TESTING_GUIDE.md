# üß™ Frontend Testing Guide - Sommelier Agent

## ‚úÖ Current Architecture Status

Your app uses:
- **Backend**: FastAPI (api/mobile_api.py) on port 8000
- **Frontend**: Streamlit (restaurants/app_fastapi_hybrid.py) on port 8501
- **LLM**: XAI Grok 3 for ALL conversation features:
  - Tasting note generation
  - Food pairing recommendations
  - Wine selection intelligence

**XAI Grok is already integrated!** ‚úÖ

---

## üìã Pre-Testing Checklist

### 1. Verify Environment Variables

Check your `.env` file has these XAI settings:

```bash
# XAI Grok Configuration (REQUIRED)
XAI_API_KEY=gAAAAABpfAn... (your encrypted key)
ENCRYPTION_KEY=lDQr_9sh6VuJc_NkAo8knjlu9di5Eocztxz_CF7a7-g=
XAI_CHAT_MODEL=grok-3
XAI_EMBEDDING_MODEL=grok-embedding

# Pinecone (REQUIRED)
PINECONE_API_KEY=pcsk_RvVS7_...
PINECONE_INDEX_NAME=wineregionscrape
PINECONE_HOST=https://wineregionscrape-skm0ode.svc.aped-4627-b74a.pinecone.io

# OpenAI (for embeddings only)
OPENAI_API_KEY=sk-proj-...
USE_OPENAI_EMBEDDINGS=true
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

**Key packages:**
- `openai>=1.3.0` (XAI uses OpenAI-compatible API)
- `fastapi>=0.110.0`
- `streamlit>=1.30.0`
- `uvicorn>=0.27.0`
- `pinecone>=5.0.0`
- `redis>=5.0.1` (optional, for caching)

---

## üöÄ Step-by-Step Testing

### Step 1: Verify Pinecone Index

Before starting the app, make sure your Pinecone index has wine data:

```bash
python check_pinecone_status.py
```

**Expected output:**
```
‚úì Pinecone connected
‚úì Index 'wineregionscrape' found
‚úì Total vectors: 282+ (maass namespace)
```

If you see 0 vectors, you need to run the data ingestion first:
```bash
python embed_maass_schema_v2.py
```

---

### Step 2: Start FastAPI Backend

**Terminal 1** - Start the backend:

```bash
python -m uvicorn api.mobile_api:app --reload --port 8000
```

**Expected output:**
```
INFO:     Started server process
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

**Test the backend:**
Open browser to http://localhost:8000/docs

You should see the FastAPI interactive API documentation (Swagger UI).

---

### Step 3: Test Backend API

**Terminal 2** - Run the test script:

```bash
python test_hybrid.py
```

**Expected output:**
```
============================================================
Testing FastAPI + Streamlit Hybrid Architecture
============================================================

[1/3] Checking FastAPI backend...
   ‚úì Backend online: Jarvis Wine Sommelier API

[2/3] Testing recommendation endpoint...
   ‚úì Recommendation successful (3.45s)
   ‚úì Wines returned: 2
   ‚úì Processing time: 3.42s

   Sample wine:
   - Antinori Tignanello
   - Region: Tuscany
   - Price: $150

[3/3] Testing cache performance...
   ‚úì Cached request (0.08s)
   ‚úì Speedup: 43.1x faster

============================================================
Backend Test Complete!
============================================================
```

**If you see errors:**
- ‚ùå "Cannot connect to backend" ‚Üí Make sure Terminal 1 is running
- ‚ùå "No wines found" ‚Üí Check Pinecone has data (Step 1)
- ‚ùå "XAI API error" ‚Üí Verify XAI_API_KEY in .env

---

### Step 4: Start Streamlit Frontend

**Terminal 3** - Start the frontend:

```bash
streamlit run restaurants/app_fastapi_hybrid.py
```

**Expected output:**
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.100:8501
```

**The app will automatically open in your browser.**

---

## üß™ Frontend Testing Checklist

### Visual Tests

Open http://localhost:8501 and verify:

1. **UI Appearance** ‚úÖ
   - [ ] Clean black and white theme loads
   - [ ] "MAASS" title appears at top
   - [ ] Jarvis introduction text is visible
   - [ ] Chat input box says "Describe the wine you're looking for..."

2. **Avatars** ‚úÖ
   - [ ] User messages show bottle icon (bottle_icon.jpeg)
   - [ ] Assistant messages show vortex icon (vortex.jpeg)

### Functional Tests

**Test Query 1: Price + Type**
```
Bold red wine for steak under $100
```

**Expected result:**
- Jarvis displays 2 red wine recommendations
- Each wine shows:
  - ‚úÖ Vintage + Producer + Wine Name
  - ‚úÖ Region + Country
  - ‚úÖ Price (within budget)
  - ‚úÖ **Tasting Note** (generated by XAI Grok)
  - ‚úÖ **Food Pairing** (generated by XAI Grok)
- Processing time badge shows (e.g., "‚ö° 3.45s")

**Test Query 2: Specific Region**
```
Full body Chianti around $125
```

**Expected result:**
- 2 Chianti wines from Tuscany
- Prices around $100-150
- Detailed tasting notes (Grok generated)
- Italian food pairings

**Test Query 3: Grape Varietal**
```
Pinot Noir from Burgundy under $200
```

**Expected result:**
- 2 French Burgundy Pinot Noir wines
- Price under $200
- Tasting notes mention "red fruit, earthy, silky"

---

## üîç Verify XAI Grok is Being Used

### Method 1: Check Backend Logs (Terminal 1)

When you make a query, you should see:

```
INFO:     POST /api/recommend
INFO:     Getting recommendations for: Bold red wine for steak under $100
INFO:     LLM selected wines: 3,7
```

The "LLM selected wines" message confirms XAI Grok is choosing wines.

### Method 2: Check Generated Content

XAI Grok generates:
1. **Tasting Notes** - Should be elegant, specific, and non-generic
   - ‚ùå Generic: "A red wine from Tuscany"
   - ‚úÖ Grok: "This Tuscan blend opens with aromas of dark cherry and violet, layered with hints of tobacco and leather. On the palate, it delivers firm tannins and bright acidity, culminating in a long, savory finish."

2. **Food Pairings** - Should be specific and varied
   - ‚ùå Generic: "Pairs well with meat"
   - ‚úÖ Grok: "Pairs well with grilled ribeye, wild mushroom risotto, and aged Parmigiano-Reggiano."

### Method 3: Check Code

Open [restaurants/wine_recommender_optimized.py:227](restaurants/wine_recommender_optimized.py#L227):

```python
response = self.grok_client.chat.completions.create(
    model=settings.xai_chat_model,  # Uses "grok-3"
    messages=[{"role": "user", "content": prompt}],
    temperature=0.7,
    max_tokens=200
)
```

This confirms XAI Grok 3 is being called.

---

## ‚ö° Performance Testing

### Cache Testing

1. Make a query: `"Bold red wine under $100"`
2. Wait for response (should take 2-5 seconds)
3. Make the EXACT SAME query again
4. Response should be <200ms (from Streamlit cache)

**Cache Layers:**
- **Streamlit Cache**: 1 hour TTL (fastest)
- **Redis Cache**: 30 days TTL (tasting notes + pairings)
- **Pinecone**: Vector search (always fast)

### Mobile Testing

1. Get your local IP address:
   ```bash
   ipconfig  # Windows
   ifconfig  # Mac/Linux
   ```

2. Open on your phone:
   ```
   http://YOUR_IP:8501/?restaurant=maass
   ```

3. Test on mobile:
   - [ ] UI is responsive
   - [ ] Chat input works
   - [ ] Wine cards are readable
   - [ ] No horizontal scrolling

---

## üêõ Troubleshooting

### Error: "Cannot connect to backend API"

**Solution:**
```bash
# Terminal 1: Make sure FastAPI is running
python -m uvicorn api.mobile_api:app --reload --port 8000
```

### Error: "XAI API connection failed"

**Solution:**
1. Check `.env` has `XAI_API_KEY`
2. Verify key is valid:
   ```bash
   python -c "from config import settings; print(settings.get_decrypted_xai_key())"
   ```
3. Check XAI account: https://console.x.ai/

### Error: "No wines found matching criteria"

**Solution:**
1. Check Pinecone has data:
   ```bash
   python check_pinecone_status.py
   ```
2. If empty, run data ingestion:
   ```bash
   python embed_maass_schema_v2.py
   ```

### Error: "Redis connection failed"

**Solution:**
Redis is **optional**. The app will fall back to in-memory caching.

To fix:
```bash
# Windows (WSL)
wsl -e redis-server

# Mac
brew install redis
redis-server

# Docker
docker run -p 6379:6379 redis
```

### Slow Response Times (>10 seconds)

**Solution:**
1. Check Redis is running (for caching)
2. Verify internet connection (API calls to XAI)
3. Use cached queries for testing
4. Check Pinecone index health

---

## üìä Success Metrics

Your frontend is working correctly if:

‚úÖ **Functionality**
- [ ] Backend API responds at http://localhost:8000
- [ ] Frontend loads at http://localhost:8501
- [ ] Chat interface accepts queries
- [ ] 2 wine recommendations appear
- [ ] Tasting notes are detailed and specific
- [ ] Food pairings are relevant

‚úÖ **Performance**
- [ ] First query: 2-10 seconds
- [ ] Cached query: <200ms
- [ ] Mobile loads in <500ms

‚úÖ **XAI Integration**
- [ ] Grok generates tasting notes
- [ ] Grok generates food pairings
- [ ] Grok selects best 2 wines from candidates
- [ ] All content is high-quality and non-generic

---

## üöÄ Next Steps After Testing

### 1. Deploy to Production

Follow: [STREAMLIT_CLOUD_DEPLOYMENT.md](STREAMLIT_CLOUD_DEPLOYMENT.md)

**Quick deploy:**
```bash
# 1. Push to GitHub
git add .
git commit -m "Ready for deployment"
git push

# 2. Deploy backend to Railway
railway login
railway init
railway up

# 3. Deploy frontend to Streamlit Cloud
# Go to: https://share.streamlit.io
# Connect your GitHub repo
# Select: restaurants/app_fastapi_hybrid.py
# Add secret: API_URL = "https://your-app.railway.app"
```

### 2. Generate QR Code

```python
import qrcode

qr = qrcode.QRCode()
qr.add_data("https://your-app.streamlit.app/?restaurant=maass")
qr.make()
qr.make_image().save("maass_qr.png")
```

Print and place QR code at MAASS restaurant tables.

### 3. Monitor Performance

```bash
# Check backend health
curl http://localhost:8000/api/health

# Check active restaurants
curl http://localhost:8000/api/restaurants
```

---

## üìù Testing Checklist Summary

Before marking complete, verify:

- [ ] All dependencies installed
- [ ] Environment variables set (especially XAI_API_KEY)
- [ ] Pinecone has wine data (282+ vectors)
- [ ] FastAPI backend running on port 8000
- [ ] Backend test passes (test_hybrid.py)
- [ ] Streamlit frontend running on port 8501
- [ ] Chat interface loads correctly
- [ ] Wine recommendations appear (2 wines)
- [ ] Tasting notes are detailed (XAI Grok generated)
- [ ] Food pairings are relevant (XAI Grok generated)
- [ ] Caching works (second query is fast)
- [ ] Mobile responsive (tested on phone)

---

## üí° Pro Tips

1. **Keep Terminal 1 running** - Backend must stay online for frontend to work
2. **Use cached queries** - Same query twice tests caching
3. **Check logs** - Terminal 1 shows all API calls
4. **Test edge cases** - Try "expensive wine", "cheap wine", "Burgundy"
5. **Mobile first** - Most users will scan QR codes on phones

---

**Status**: ‚úÖ Ready to test!

**Estimated testing time**: 15-20 minutes

**Questions?** Check [HYBRID_ARCHITECTURE_SUMMARY.md](HYBRID_ARCHITECTURE_SUMMARY.md) for architecture details.
